{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d35976",
   "metadata": {},
   "source": [
    "## Stage 3: What do I need to install?\n",
    "Typical python dependency management (https://xkcd.com/1987/):\n",
    "\n",
    "<img src=https://imgs.xkcd.com/comics/python_environment.png>\n",
    "\n",
    "Add in data science packages that have all sorts of additional non-Python dependencies and we end up spending more time sorting out our dependencies than doing data science. If you take home nothing else out of this tutorial, learn this stage. I promise. It will save you, and everyone who works with you, many days of your life back.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a175ea32",
   "metadata": {},
   "source": [
    "### Reproducibility Issues:\n",
    "* (NO-ENVIRONMENT-INSTRUCTIONS) Chicken and egg issue with environments. No environment.yml file or the like. (Even if there are some instructions in a notebook).\n",
    "* (NO-VERSION-PIN) Versions not pinned. E.g. uses a dev branch without a clear indication of when it became released.\n",
    "* (IMPOSSIBLE-ENVIRONMENT) dependencies are not resolvable due to version clashes. (e.g. need <=0.48 and >=0.49)\n",
    "* (ARCH-DIFFERENCE) The same code runs differently on different architectures\n",
    "* (MONOLITHIC-ENVIRONMENT) One environment to rule (or fail) them all. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf99f769",
   "metadata": {},
   "source": [
    "\n",
    "### Default Better Principles\n",
    "* **Use (at least) one virtual environment per repo**: And use the same name for the environment as the repo.\n",
    "* **Generate lock files**: Lock files include every single dependency in your dependency chain. Lock files are necessarily platform specific, so you need one per platform that you support. This way you have a perfect version pin on the environment that you used for that moment in time.\n",
    "* **Check in your environment creation instructions**: That means an `environment.yml` file for conda, and its matching lock file(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2a6077",
   "metadata": {},
   "source": [
    "## The Easydata way: `make create_environment`\n",
    "We like `conda` for environment management since it's the least bad option for most data science workflows. There are no perfect ways of doing this. Here are some basics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5184965d",
   "metadata": {},
   "source": [
    "First, a cell that lets us reload without having to kill the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8d72c",
   "metadata": {},
   "source": [
    "### Setting up your environment\n",
    "**WARNING**: If you have conda-forge listed as a channel in your `.condarc` (or any other channels other than defaults), you may experience great difficulty generating reproducible conda environments.\n",
    "\n",
    "We recommend you remove conda-forge (and all other non-default channels) from your `.condarc` file and [set your channel priority to 'strict'](https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-channels.html). Alternate channels can be specified explicitly in your your `environment.yml` by prefixing your package name with `channel-name::`; e.g.\n",
    "\n",
    "```\n",
    "  - wheel                    # install from the default (anaconda) channel\n",
    "  - pytorch::pytorch         # install this from the `pytorch` channel\n",
    "  - conda-forge::tokenizers  # install this from conda-forge\n",
    "```\n",
    "\n",
    "### Initial setup\n",
    "\n",
    "* Make note of the path to your conda binary:\n",
    "```\n",
    "   $ which conda\n",
    "   ~/miniconda3/bin/conda\n",
    "```\n",
    "* ensure your `CONDA_EXE` environment variable is set to this value (or edit `Makefile.include` directly)\n",
    "```\n",
    "    export CONDA_EXE=~/miniconda3/bin/conda\n",
    "```\n",
    "* Create and switch to the virtual environment:\n",
    "```\n",
    "cd easydata-tutorial\n",
    "make create_environment\n",
    "conda activate easydata-tutorial\n",
    "```\n",
    "\n",
    "Now you're ready to run `jupyter notebook` (or jupyterlab) and explore the notebooks in the `notebooks` directory.\n",
    "\n",
    "For more instructions on setting up and maintaining your environment (including how to point your environment at your custom forks and work in progress) see [Setting up and Maintaining your Conda Environment Reproducibly](../reference/easydata/conda-environments.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be18d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fac01d",
   "metadata": {},
   "source": [
    "## Maintaining your Python environment\n",
    "\n",
    "### Updating your conda and pip environments\n",
    "The `make` commands, `make create_environment` and `make update_environment` are wrappers that allow you to easily manage your conda and pip environments using the `environment.yml` file.\n",
    "\n",
    "(If you ever forget which `make` command to run, you can run `make` by itself and it will provide a list of commands that are available.)\n",
    "\n",
    "\n",
    "When adding packages to your python environment, **do not `pip install` or `conda install` directly**. Always edit `environment.yml` and `make update_environment` instead.\n",
    "\n",
    "Your `environment.yml` file will look something like this:\n",
    "```\n",
    "name: easydata-tutorial\n",
    "  - pip\n",
    "  - pip:\n",
    "    - -e .  # conda >= 4.4 only\n",
    "    - python-dotenv>=0.5.1\n",
    "    - nbval\n",
    "    - nbdime\n",
    "    - umap-learn\n",
    "    - gdown\n",
    "  - setuptools\n",
    "  - wheel\n",
    "  - git>=2.5  # for git worktree template updating\n",
    "  - sphinx\n",
    "  - bokeh\n",
    "  - click\n",
    "  - colorcet\n",
    "  - coverage\n",
    "  - coveralls\n",
    "  - datashader\n",
    "  - holoviews\n",
    "  - matplotlib\n",
    "  - jupyter\n",
    "...\n",
    "```\n",
    "To add any package available from conda, add it to the end of the list. If you have a PYPI dependency that's not avaible via conda, add it to the list of pip installable dependencies under `  - pip:`.\n",
    "\n",
    "You can include any github.com python-based project in the `pip` section via `git+https://github.com/<my_git_handle>/<package>`.\n",
    "\n",
    "In particular, if you're working off of a fork or a work in progress branch of a repo in github.com (say, your personal version of <package>), you can change `git+https://github.com/<my_git_handle>/<package>` to\n",
    "\n",
    "* `git+https://github.com/<my_git_handle>/<package>.git` to point to the main branch of your fork and\n",
    "* `git+https://github.com/<my_git_handle>/<package>.git@<my branch>` to point to a specific branch.\n",
    "\n",
    "Once you're done your edits, run `make update_environment` and voila, you're updated.\n",
    "\n",
    "To share your updated environment, check in your `environment.yml` file. (More on this in [Sharing your Work](sharing-your-work.md))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a18ca",
   "metadata": {},
   "source": [
    "Now try updating your environment to include `seaborn`. But first:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fbbd52",
   "metadata": {},
   "source": [
    "#### Using your conda environment in a jupyter notebook\n",
    "If you make a new notebook, select the `easydata-tutorial` environment from within the notebook. If you are somehow in another kernel, select **Kernel -> Change kernel -> Python[conda env:easydata-tutorial]**. If you don't seem to have that option, make sure that you ran `jupyter notebooks` with the `easydata-tutorial` conda environment enabled, and that `which jupyter` points to the correct (`easydata-tutorial`) version of jupyter.\n",
    "\n",
    "If you want your environment changes (or `src` module edits) to be immediately available in your running notebooks, make sure to run a notebook cell containing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8af60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95d2d12",
   "metadata": {},
   "source": [
    "#### Lock files\n",
    "Now, we'll admit that this workflow isn't perfectly reproducible in the sense that conda still has to resolve versions from the `environment.yml`. To make it more reproducible, running either `make create_environment` or `make update_environment` will generate an `environment.{$ARCH}.lock.yml` (e.g. `environment.i386.lock.yml`). This file keeps a record of the exact environment that is currently installed in your conda environment `easydata-tutorial`. If you ever need to reproduce an environment exactly, you can install from the `.lock.yml` file. (Note: These are architecture dependent)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c72360",
   "metadata": {},
   "source": [
    "Run `make env_challenge` to complete this Challenge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:easydata-tutorial] *",
   "language": "python",
   "name": "conda-env-easydata-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
