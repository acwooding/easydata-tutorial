{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "998fbc9b",
   "metadata": {},
   "source": [
    "This dataset is created using the template for creating a dataset from scratch as in: https://cookiecutter-easydata.readthedocs.io/en/latest/New-Dataset-Template/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd47272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:51,274 - utils - INFO - NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "# Basic utility functions\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "from pprint import pprint\n",
    "\n",
    "from src.log import logger\n",
    "from src import paths\n",
    "from src.utils import list_dir\n",
    "from functools import partial\n",
    "\n",
    "# data functions\n",
    "from src.data import DataSource, Dataset, DatasetGraph, Catalog\n",
    "from src import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ab2e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally set to debug log level\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e22eea",
   "metadata": {},
   "source": [
    "## Create the Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7faedcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = 'dataset-challenge'\n",
    "dsrc = DataSource(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37d90b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "license = \"\"\"\n",
    "CC-BY-4.0 is a common form of dataset license. Here you would put the license for your data, along with any attribution and other information necessary to keep in line with the terms included in the original license.\n",
    "\n",
    "All data that you use should have an explicit license kept with it. To keep the license with the data, Easydata uses a license as one of its metadata fields which can be accessed via\n",
    "\n",
    "`.LICENSE`\n",
    "\n",
    "for any Dataset object.\n",
    "\n",
    "For more on licenses, see the references at the end of the `04-Data-Challenge` notebook.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86edc148",
   "metadata": {},
   "outputs": [],
   "source": [
    "descr = \"\"\"\n",
    "The `.DESCR` is where Easydata keeps a description of the dataset. In this example, you'll see that we have a Dataset object container with metadata, but no data.\n",
    "\n",
    "For this dataset, if you do a ds.data, you will return NONE. \n",
    "\n",
    "A basic description of the data is something that always stays with the data, Easydata uses a descr as one of its metadata fields which can be accessed via\n",
    "\n",
    "`.DESCR`\n",
    "\n",
    "for any Dataset object.\n",
    "\n",
    "When you transform the data, it is nice to append new information including what has been done to the data via the transformation by appending information to the end of the `.DESCR` text.\n",
    "\n",
    "You can add any metadata you want to ds.metdata, as it is basically a dict with a fancy wrapping paper that lets you access any key via ALL CAPS.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba3994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.add_metadata(contents=descr, force=True)\n",
    "dsrc.add_metadata(contents=license, kind='LICENSE', force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "136930ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.extra import process_extra_files\n",
    "process_function = process_extra_files\n",
    "process_function_kwargs = {'file_glob':'*.csv',\n",
    "                           'do_copy': True,\n",
    "                           'extra_dir': ds_name+'.extra',\n",
    "                           'extract_dir': ds_name}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21b6bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc.process_function = partial(process_function, **process_function_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eac4b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:51,807 - catalog - DEBUG - Loaded 2 records from 'datasources' Catalog.\n",
      "2021-10-26 10:12:51,810 - catalog - DEBUG - Verifying serialization for catalog 'datasources'\n",
      "2021-10-26 10:12:51,815 - catalog - DEBUG - Writing entry:'dataset-challenge' to catalog:'datasources'.\n",
      "2021-10-26 10:12:51,817 - datasets - DEBUG - Updated datasource:dataset-challenge in catalog\n"
     ]
    }
   ],
   "source": [
    "dsrc.update_catalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd14fa7",
   "metadata": {},
   "source": [
    "## Create the Corresponding Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14c33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import DatasetGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba4b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:51,851 - catalog - DEBUG - Loaded 3 records from 'transformers' Catalog.\n",
      "2021-10-26 10:12:51,853 - catalog - DEBUG - Verifying serialization for catalog 'transformers'\n",
      "2021-10-26 10:12:51,857 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:51,858 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n",
      "2021-10-26 10:12:51,863 - datasets - DEBUG - Loaded DatasetGraph with 3 nodes and 3 edges.\n"
     ]
    }
   ],
   "source": [
    "dag = DatasetGraph(catalog_path=paths['catalog_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84d4a1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:51,873 - catalog - DEBUG - Writing entry:'_dataset-challenge' to catalog:'transformers'.\n",
      "2021-10-26 10:12:51,877 - datasets - INFO - Regenerating output Dataset 'dataset-challenge' and adding to catalog\n",
      "2021-10-26 10:12:51,878 - datasets - DEBUG - Generating edge traversal list for Dataset:'dataset-challenge'\n",
      "2021-10-26 10:12:51,879 - datasets - DEBUG - traverse: examining vertex:'dataset-challenge'\n",
      "2021-10-26 10:12:51,880 - datasets - DEBUG - traverse: all input dependencies:[] satisfied for edge: '_dataset-challenge'\n",
      "2021-10-26 10:12:51,881 - datasets - DEBUG - Traversal complete. Edges to process: ['_dataset-challenge']\n",
      "2021-10-26 10:12:51,882 - datasets - DEBUG - process_edge: Processing input datasets for edge:'_dataset-challenge'\n",
      "2021-10-26 10:12:51,883 - datasets - DEBUG - process_edge:Applying transformer: {'transformer_module': 'src.data.datasets', 'transformer_name': 'dataset_from_datasource', 'transformer_kwargs': {'dataset_name': 'dataset-challenge', 'datasource_name': 'dataset-challenge'}} to input datasets: []\n",
      "2021-10-26 10:12:51,888 - catalog - DEBUG - Loaded 2 records from 'datasources' Catalog.\n",
      "2021-10-26 10:12:51,889 - catalog - DEBUG - Verifying serialization for catalog 'datasources'\n",
      "2021-10-26 10:12:51,894 - fetch - DEBUG - Generating dataset-challenge.readme hash...\n",
      "2021-10-26 10:12:51,897 - fetch - DEBUG - Generating dataset-challenge.license hash...\n",
      "2021-10-26 10:12:51,901 - fetch - DEBUG - Copying dataset-challenge.readme...\n",
      "2021-10-26 10:12:51,904 - fetch - DEBUG - Copying dataset-challenge.license...\n",
      "2021-10-26 10:12:51,912 - extra - DEBUG - Do copy: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba0542635c4499a8a9412dfd6a6da5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:51,944 - datasets - INFO - Generated output datasets: ['dataset-challenge'] via edge:'_dataset-challenge'\n",
      "2021-10-26 10:12:51,949 - datasets - DEBUG - Updating hashes for dataset 'dataset-challenge': {'hashes': {'data': 'sha1:38f65f3b11da4851aaaccc19b1f0cf4d3806f83b', 'target': 'sha1:38f65f3b11da4851aaaccc19b1f0cf4d3806f83b'}}.\n",
      "2021-10-26 10:12:51,950 - datasets - DEBUG - process_edge: Updating catalog entry for dataset-challenge\n",
      "2021-10-26 10:12:51,951 - catalog - DEBUG - Writing entry:'dataset-challenge' to catalog:'datasets'.\n",
      "2021-10-26 10:12:51,953 - datasets - DEBUG - process_edge: Overwriting 'dataset-challenge' in `dataset_path`\n",
      "2021-10-26 10:12:51,955 - datasets - DEBUG - Updating hashes for dataset 'dataset-challenge': {'hashes': {'data': 'sha1:38f65f3b11da4851aaaccc19b1f0cf4d3806f83b', 'target': 'sha1:38f65f3b11da4851aaaccc19b1f0cf4d3806f83b'}}.\n",
      "2021-10-26 10:12:51,958 - datasets - DEBUG - Wrote Dataset Metadata: dataset-challenge.metadata\n",
      "2021-10-26 10:12:51,959 - datasets - DEBUG - Re-scanning Dataset catalog before update\n",
      "2021-10-26 10:12:51,963 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:51,964 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n",
      "2021-10-26 10:12:51,967 - catalog - DEBUG - Writing entry:'dataset-challenge' to catalog:'datasets'.\n",
      "2021-10-26 10:12:51,969 - datasets - DEBUG - Updated dataset catalog with 'dataset-challenge' metadata\n",
      "2021-10-26 10:12:51,971 - datasets - DEBUG - Wrote Dataset: dataset-challenge.dataset\n",
      "2021-10-26 10:12:51,972 - datasets - DEBUG - process_edge: Reloading Dataset catalog after processing edge:'_dataset-challenge'\n",
      "2021-10-26 10:12:51,975 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:51,976 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_dataset-challenge': {'transformations': [{'transformer_module': 'src.data.datasets',\n",
       "    'transformer_name': 'dataset_from_datasource',\n",
       "    'transformer_kwargs': {'dataset_name': 'dataset-challenge',\n",
       "     'datasource_name': 'dataset-challenge'}}],\n",
       "  'output_datasets': ['dataset-challenge']}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag.add_source(output_dataset=ds_name, datasource_name=ds_name, overwrite_catalog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78ca4c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:52,009 - catalog - DEBUG - Loaded 3 records from 'transformers' Catalog.\n",
      "2021-10-26 10:12:52,011 - catalog - DEBUG - Verifying serialization for catalog 'transformers'\n",
      "2021-10-26 10:12:52,015 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:52,017 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n",
      "2021-10-26 10:12:52,020 - datasets - DEBUG - Loaded DatasetGraph with 3 nodes and 3 edges.\n",
      "2021-10-26 10:12:52,021 - datasets - DEBUG - Generating edge traversal list for Dataset:'dataset-challenge'\n",
      "2021-10-26 10:12:52,022 - datasets - DEBUG - traverse: examining vertex:'dataset-challenge'\n",
      "2021-10-26 10:12:52,023 - datasets - DEBUG - traverse: all input dependencies:[] satisfied for edge: '_dataset-challenge'\n",
      "2021-10-26 10:12:52,024 - datasets - DEBUG - Traversal complete. Edges to process: ['_dataset-challenge']\n",
      "2021-10-26 10:12:52,028 - datasets - DEBUG - process_edge: Processing input datasets for edge:'_dataset-challenge'\n",
      "2021-10-26 10:12:52,029 - datasets - DEBUG - process_edge:Applying transformer: {'transformer_kwargs': {'dataset_name': 'dataset-challenge', 'datasource_name': 'dataset-challenge'}, 'transformer_module': 'src.data.datasets', 'transformer_name': 'dataset_from_datasource'} to input datasets: []\n",
      "2021-10-26 10:12:52,032 - catalog - DEBUG - Loaded 2 records from 'datasources' Catalog.\n",
      "2021-10-26 10:12:52,033 - catalog - DEBUG - Verifying serialization for catalog 'datasources'\n",
      "2021-10-26 10:12:52,039 - fetch - DEBUG - Generating dataset-challenge.readme hash...\n",
      "2021-10-26 10:12:52,043 - fetch - DEBUG - Generating dataset-challenge.license hash...\n",
      "2021-10-26 10:12:52,047 - fetch - DEBUG - Copying dataset-challenge.readme...\n",
      "2021-10-26 10:12:52,049 - fetch - DEBUG - Copying dataset-challenge.license...\n",
      "2021-10-26 10:12:52,059 - extra - DEBUG - Do copy: True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d2c8a3f6bd41a89b9dd0ef6b5af8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:52,105 - datasets - INFO - Generated output datasets: ['dataset-challenge'] via edge:'_dataset-challenge'\n",
      "2021-10-26 10:12:52,112 - datasets - DEBUG - Updating hashes for dataset 'dataset-challenge': {'hashes': {'data': 'sha1:38f65f3b11da4851aaaccc19b1f0cf4d3806f83b', 'target': 'sha1:38f65f3b11da4851aaaccc19b1f0cf4d3806f83b'}}.\n",
      "2021-10-26 10:12:52,113 - datasets - DEBUG - process_edge: Reloading Dataset catalog after processing edge:'_dataset-challenge'\n",
      "2021-10-26 10:12:52,122 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:52,123 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_catalog(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3791e3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-26 10:12:52,157 - catalog - DEBUG - Loaded 3 records from 'transformers' Catalog.\n",
      "2021-10-26 10:12:52,160 - catalog - DEBUG - Verifying serialization for catalog 'transformers'\n",
      "2021-10-26 10:12:52,164 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:52,166 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n",
      "2021-10-26 10:12:52,168 - datasets - DEBUG - Loaded DatasetGraph with 3 nodes and 3 edges.\n",
      "2021-10-26 10:12:52,169 - datasets - DEBUG - Verifying hashes using Dataset catalog.\n",
      "2021-10-26 10:12:52,173 - catalog - DEBUG - Loaded 3 records from 'datasets' Catalog.\n",
      "2021-10-26 10:12:52,175 - catalog - DEBUG - Verifying serialization for catalog 'datasets'\n",
      "2021-10-26 10:12:52,179 - datasets - DEBUG - Load dataset-challenge from disk...\n",
      "2021-10-26 10:12:52,181 - datasets - DEBUG - Loaded dataset-challenge from disk.\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.load(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0847a712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The `.DESCR` is where Easydata keeps a description of the dataset. In this example, you'll see that we have a Dataset object container with metadata, but no data.\n",
      "\n",
      "For this dataset, if you do a ds.data, you will return NONE. \n",
      "\n",
      "A basic description of the data is something that always stays with the data, Easydata uses a descr as one of its metadata fields which can be accessed via\n",
      "\n",
      "`.DESCR`\n",
      "\n",
      "for any Dataset object.\n",
      "\n",
      "When you transform the data, it is nice to append new information including what has been done to the data via the transformation by appending information to the end of the `.DESCR` text.\n",
      "\n",
      "You can add any metadata you want to ds.metdata, as it is basically a dict with a fancy wrapping paper that lets you access any key via ALL CAPS.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a561e4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CC-BY-4.0 is a common form of dataset license. Here you would put the license for your data, along with any attribution and other information necessary to keep in line with the terms included in the original license.\n",
      "\n",
      "All data that you use should have an explicit license kept with it. To keep the license with the data, Easydata uses a license as one of its metadata fields which can be accessed via\n",
      "\n",
      "`.LICENSE`\n",
      "\n",
      "for any Dataset object.\n",
      "\n",
      "For more on licenses, see the references at the end of the `04-Data-Challenge` notebook.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ds.LICENSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f639735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.EXTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf29e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c255e7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:easydata-tutorial] *",
   "language": "python",
   "name": "conda-env-easydata-tutorial-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
